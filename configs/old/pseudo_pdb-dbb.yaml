source:
  - name: DebugBench_cache
    type: json
    kwargs:
      path: results/dbb-testcase/results_merged_1.json
      sort_key: id
dataset:
  - name: target
    type: dict
    kwargs:
      primary_key: id
      fields:
        - name: id
          source: DebugBench_cache
          key: id
        - name: question
          source: DebugBench_cache
          key: question
        - name: wrong_code
          source: DebugBench_cachez
          key: wrong_code
        - name: right_code
          source: DebugBench_cache
          key: right_code
        - name: testcase_inputs
          source: DebugBench_cache
          key: testcase_inputs

# conda activate ArchCode
# export PYTHONPATH="third_party/expand_langchain:$PYTHONPATH"
# python run.py generator --config_path=configs/pseudo_pdb-dbb.yaml --rerun=False --max_concurrency=16 - run --start=0 --end=80 - merge_json - exit
# python run.py generator --config_path=configs/pseudo_pdb-dbb.yaml --rerun=False --max_concurrency=16 - run --start=80 --end=160 - merge_json - exit
# python run.py generator --config_path=configs/pseudo_pdb-dbb.yaml --rerun=False --max_concurrency=16 - run --start=160 --end=-1 - merge_json - exit
graph:
  entry_point: initialize

  edges:
    - pair: [initialize, __end__]
      type: always

  nodes:
    - name: initialize
      chains:
        - name: pseudocode
          dependencies: []
          input_keys: [question]
          type: cot
          kwargs:
            llm:
              max_tokens: 4096
              model: llama3.1:70b-instruct-fp16
              platform: open_webui
              temperature: 0
              top_p: 1
            parsers:
              - type: code_block
            prompt:
              type: chat
              kwargs:
                body_template_paths: ["templates/pseudocode"]

        - name: pseudo_pdb
          dependencies: [pseudocode]
          input_keys: [question, pseudocode, testcase_inputs]
          key_map: { testcase_inputs: testcase }
          type: cot
          kwargs:
            llm:
              max_tokens: 4096
              model: llama3.1:70b-instruct-fp16
              platform: open_webui
              temperature: 0
              top_p: 1
            parsers:
              - type: code_block
              - type: load_json
            prompt:
              type: chat
              kwargs:
                body_template_paths: ["templates/pseudo_pdb"]

        - name: gen_testcases_str
          dependencies: [pseudo_pdb]
          input_keys: [testcase_inputs, pseudo_pdb]
          type: custom_lambda
          kwargs:
            distribute: False
            src: ["testcase_inputs", "pseudo_pdb"]
            func: |
              def func(testcases, pseudo_pdb):
                  import json
                  data = [
                      input + f"\n Output: {output['final_output']}"
                      for input, output in zip(testcases, pseudo_pdb)
                  ]
                  return json.dumps(data, indent=2, ensure_ascii=False)

        - name: _wrong_exec_code
          dependencies: [gen_testcases_str]
          input_keys: [question, gen_testcases_str, wrong_code]
          key_map: { gen_testcases_str: testcases, wrong_code: code }
          type: cot
          kwargs:
            llm:
              max_tokens: 4096
              model: llama3.1:70b-instruct-fp16
              platform: open_webui
              temperature: 0
              top_p: 1
            parsers:
              - type: code_block
              - type: load_json
            prompt:
              type: chat
              kwargs:
                body_template_paths: ["templates/exec_code-dbb"]
        - name: wrong_exec_code
          dependencies: [_wrong_exec_code]
          input_keys: [_wrong_exec_code, wrong_code]
          key_map: { _wrong_exec_code: testcase, wrong_code: code }
          type: custom_lambda
          kwargs:
            src: ["testcase", "code"]
            func: |
              def func(testcase, code):
                  imports = testcase["imports"]
                  return [
                      imports + "\n" + code + "\n" + assertion
                      for assertion in testcase["assertions"]
                  ]
        - name: wrong_exec_result
          dependencies: [wrong_exec_code]
          input_keys: [wrong_exec_code]
          key_map: { wrong_exec_code: exec_code }
          type: execute
          kwargs:
            code_key: exec_code
            timeout: 10

        - name: _right_exec_code
          dependencies: [gen_testcases_str]
          input_keys: [question, gen_testcases_str, right_code]
          key_map: { gen_testcases_str: testcases, right_code: code }
          type: cot
          kwargs:
            llm:
              max_tokens: 4096
              model: llama3.1:70b-instruct-fp16
              platform: open_webui
              temperature: 0
              top_p: 1
            parsers:
              - type: code_block
              - type: load_json
            prompt:
              type: chat
              kwargs:
                body_template_paths: ["templates/exec_code-dbb"]
        - name: right_exec_code
          dependencies: [_right_exec_code]
          input_keys: [_right_exec_code, right_code]
          key_map: { _right_exec_code: testcase, right_code: code }
          type: custom_lambda
          kwargs:
            src: ["testcase", "code"]
            func: |
              def func(testcase, code):
                  imports = testcase["imports"]
                  return [
                      imports + "\n" + code + "\n" + assertion
                      for assertion in testcase["assertions"]
                  ]
        - name: right_exec_result
          dependencies: [right_exec_code]
          input_keys: [right_exec_code]
          key_map: { right_exec_code: exec_code }
          type: execute
          kwargs:
            code_key: exec_code
            timeout: 10
