source:
  - name: code_contests
    type: json
    kwargs:
      sort_key: id
      path: results/20240924_pseudocode/splitted.json
  - name: example
    type: yaml
    kwargs:
      sort_key: id
      path: configs/20240924/icl_examples-codecontests.yaml

dataset:
  - name: target
    type: dict
    kwargs:
      primary_key: id
      fields:
        - name: id
          source: code_contests
          key: id
        - name: problem
          source: code_contests
          key: problem
        - name: solution
          source: code_contests
          key: solution
        - name: tc_input
          source: code_contests
          key: tc_input
        - name: tc_output
          source: code_contests
          key: tc_output
  - name: example
    type: dict
    kwargs:
      primary_key: id
      fields:
        - name: id
          source: example
          key: id
        - name: problem
          source: example
          key: question
        - name: pseudocode
          source: example
          # key: pc_lbl
          # key: pc_func
          key: pc_nl

# cd ~/Projects/InsertAssertLLM
# conda activate ArchCode
# export PYTHONPATH="third_party/expand_langchain:$PYTHONPATH"
# python run.py generator --config_path=configs/20240924/gpt_configs/20240924-gpt-pc_pred-nl.yaml --rerun=True --max_concurrency=8 - run - merge_json - exit
graph:
  entry_point: initialize

  edges:
    - pair: [initialize, __end__]
      type: always

  nodes:
    - name: initialize
      chains:
        - name: pc_pred-nl
          dependencies: []
          input_keys: [problem]
          type: cot
          kwargs:
            flatten: true
            llm:
              max_tokens: 8192
              model: gpt-4o-mini
              platform: openai
              temperature: 0
              top_p: 1
            prompt:
              type: chat
              kwargs:
                body_template_paths: ["configs/20240924/templates/pc_pred-nl"]
